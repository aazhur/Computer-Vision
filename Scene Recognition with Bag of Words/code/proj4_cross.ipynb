{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Scene Recognition with Bag-of-Words](https://www.cc.gatech.edu/~hays/compvision/proj4/)\n",
    "For this project, you will need to report performance for three\n",
    "combinations of features / classifiers. It is suggested you code them in\n",
    "this order, as well:\n",
    "1. Tiny image features and nearest neighbor classifier\n",
    "2. Bag of sift features and nearest neighbor classifier\n",
    "3. Bag of sift features and linear SVM classifier\n",
    "\n",
    "The starter code is initialized to 'placeholder' just so that the starter\n",
    "code does not crash when run unmodified and you can get a preview of how\n",
    "results are presented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "5 2 1 10 6\n",
      "0.5406666666666666 0.18419072241082668 NN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhurikhinaa/miniconda2/envs/cs6476p4/lib/python3.5/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=20000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6206666666666667 0.24447131165480795 SVM linear\n",
      "[5, 2, 1, 10, 6, 0.5406666666666666, 0.6206666666666667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhurikhinaa/miniconda2/envs/cs6476p4/lib/python3.5/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=20000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Set up parameters, image paths and category list\n",
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import pickle\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "import student_code as sc\n",
    "\n",
    "\n",
    "# This is the list of categories / directories to use. The categories are\n",
    "# somewhat sorted by similarity so that the confusion matrix looks more\n",
    "# structured (indoor and then urban and then rural).\n",
    "categories = ['Kitchen', 'Store', 'Bedroom', 'LivingRoom', 'Office', 'Industrial', 'Suburb',\n",
    "              'InsideCity', 'TallBuilding', 'Street', 'Highway', 'OpenCountry', 'Coast',\n",
    "              'Mountain', 'Forest'];\n",
    "# This list of shortened category names is used later for visualization\n",
    "abbr_categories = ['Kit', 'Sto', 'Bed', 'Liv', 'Off', 'Ind', 'Sub',\n",
    "                   'Cty', 'Bld', 'St', 'HW', 'OC', 'Cst',\n",
    "                   'Mnt', 'For'];\n",
    "\n",
    "# Number of training examples per category to use. Max is 100. For\n",
    "# simplicity, we assume this is the number of test cases per category, as\n",
    "# well.\n",
    "num_train_per_cat = 100\n",
    "\n",
    "# This function returns lists containing the file path for each train\n",
    "# and test image, as well as lists with the label of each train and\n",
    "# test image. By default all four of these lists will have 1500 elements\n",
    "# where each element is a string.\n",
    "data_path = osp.join('..', 'data')\n",
    "'''\n",
    "steps = [5, 10, 20, 30, 40, 50]\n",
    "C_value = [1, 2, 3, 4, 5, 10]\n",
    "gamma_value = [0.1, 0.2, 0.3, 0.4, 0.5, 1]\n",
    "vocab_steps = [5, 10, 20, 30]\n",
    "bins = [3, 6, 9, 12]\n",
    "'''\n",
    "\n",
    "steps = [5, 10]\n",
    "C_value = [1, 2, 3]\n",
    "gamma_value = [0.5, 1, 1.5]\n",
    "vocab_steps = [5, 10, 20]\n",
    "bins = [3, 6, 9]\n",
    "\n",
    "s = 5\n",
    "C = 3\n",
    "gamma = 1\n",
    "vs = 20\n",
    "vb = 9\n",
    "    \n",
    "hyper = [0, 0, 0, 0, 0, 0, 0];\n",
    "\n",
    "#for vs in vocab_steps:\n",
    "#    for vb in bins:\n",
    "train_image_paths, test_image_paths, train_labels, test_labels = get_image_paths(data_path,\n",
    "                                                                                 categories,\n",
    "                                                                                 num_train_per_cat);\n",
    "\n",
    "vocab_filename = 'vocab_50.pkl'\n",
    "\n",
    "vocab_size = 50  # Larger values will work better (to a point) but be slower to compute\n",
    "vocab = sc.build_vocabulary(train_image_paths, vocab_size, vs, vb)\n",
    "with open(vocab_filename, 'wb') as f:\n",
    "    pickle.dump(vocab, f)\n",
    "\n",
    "train_image_feats = sc.get_bags_of_sifts(train_image_paths, vocab_filename, s)\n",
    "test_image_feats = sc.get_bags_of_sifts(test_image_paths, vocab_filename, s)\n",
    "\n",
    "print(s, C, gamma, vs, vb)\n",
    "\n",
    "predicted_categories = sc.nearest_neighbor_classify(train_image_feats, train_labels, test_image_feats)\n",
    "cat2idx = {cat: idx for idx, cat in enumerate(categories)}\n",
    "y_true = [cat2idx[cat] for cat in test_labels]\n",
    "y_pred = [cat2idx[cat] for cat in predicted_categories]\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm = cm.astype(np.float) / cm.sum(axis=1)[:, np.newaxis]\n",
    "acc1 = np.mean(np.diag(cm))\n",
    "sd = np.std(np.diag(cm))\n",
    "print(acc1, sd, 'NN')\n",
    "\n",
    "predicted_categories = sc.svm_classify(train_image_feats, train_labels, test_image_feats, 'linear', gamma, C)\n",
    "cat2idx = {cat: idx for idx, cat in enumerate(categories)}\n",
    "y_true = [cat2idx[cat] for cat in test_labels]\n",
    "y_pred = [cat2idx[cat] for cat in predicted_categories]\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm = cm.astype(np.float) / cm.sum(axis=1)[:, np.newaxis]\n",
    "acc2 = np.mean(np.diag(cm))\n",
    "sd = np.std(np.diag(cm))\n",
    "print(acc2, sd, 'SVM linear')\n",
    "\n",
    "if acc1 >= hyper[5] and acc2 >= hyper[6]:\n",
    "    hyper = [s,C,gamma,vs,vb, acc1, acc2]\n",
    "\n",
    "print(hyper)                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
